{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Science and Artificial Intelligence\n",
    "\n",
    "## Deep Learning -  PyTorch I - Introduction and Linear Regression\n",
    "\n",
    "- [WEIDMAN] Ch7\n",
    "- https://pytorch.org/tutorials/\n",
    "- https://github.com/yunjey/pytorch-tutorial\n",
    "\n",
    "Here we introduce PyTorch, an increasingly popular neural network framework based on **automatic differentiation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    "\n",
    "- Try to play around, change some neurons, and see what happens\n",
    "- Plot the model line using <code>model.linear.weight.item()</code> and <code>model.linear.bias.item()</code>\n",
    "- Try to load the boston dataset and learn to map the data to tensorDataset\n",
    "- Try to plot the loss over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y  = load_boston()['data'] , load_boston()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.3000, 21.9000, 25.0000, 32.2000, 43.1000, 24.8000, 25.0000, 33.0000,\n",
      "        24.7000, 33.2000])\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(train_dl):\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, n_feature, size_hidden, n_output):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(n_feature, size_hidden)   # hidden layer\n",
    "        self.fc2 = torch.nn.Linear(size_hidden, 10) \n",
    "        self.fc3 = torch.nn.Linear(10, n_output)   # output layer\n",
    "        self.relu   = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out =  self.fc1(x)   # activation function for hidden layer\n",
    "        out =  self.relu(out)\n",
    "        out =  self.fc2(out)\n",
    "        out =  self.relu(out)\n",
    "        out =  self.fc3(out)                 \n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feature = X_train.shape[1]\n",
    "size_hidden = 30\n",
    "n_output = 1\n",
    "learning_rate = 0.001\n",
    "num_epoch = 300\n",
    "\n",
    "model = NeuralNet(n_feature, size_hidden, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of NeuralNet(\n",
       "  (fc1): Linear(in_features=13, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=10, bias=True)\n",
       "  (fc3): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.1647,  0.1370, -0.1647, -0.1222, -0.1728,  0.1358, -0.0408,  0.1297,\n",
       "        -0.0876,  0.1454], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 13])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[9.2660e-02, 3.4000e+01, 6.0900e+00, 0.0000e+00, 4.3300e-01, 6.4950e+00,\n",
       "          1.8400e+01, 5.4917e+00, 7.0000e+00, 3.2900e+02, 1.6100e+01, 3.8361e+02,\n",
       "          8.6700e+00],\n",
       "         [6.5388e+00, 0.0000e+00, 1.8100e+01, 1.0000e+00, 6.3100e-01, 7.0160e+00,\n",
       "          9.7500e+01, 1.2024e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.9205e+02,\n",
       "          2.9600e+00],\n",
       "         [1.1329e-01, 3.0000e+01, 4.9300e+00, 0.0000e+00, 4.2800e-01, 6.8970e+00,\n",
       "          5.4300e+01, 6.3361e+00, 6.0000e+00, 3.0000e+02, 1.6600e+01, 3.9125e+02,\n",
       "          1.1380e+01],\n",
       "         [1.4236e+01, 0.0000e+00, 1.8100e+01, 0.0000e+00, 6.9300e-01, 6.3430e+00,\n",
       "          1.0000e+02, 1.5741e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.9690e+02,\n",
       "          2.0320e+01],\n",
       "         [4.3488e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 5.8000e-01, 6.1670e+00,\n",
       "          8.4000e+01, 3.0334e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.9690e+02,\n",
       "          1.6290e+01],\n",
       "         [5.7312e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 5.3200e-01, 7.0610e+00,\n",
       "          7.7000e+01, 3.4106e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.9528e+02,\n",
       "          7.0100e+00],\n",
       "         [1.0084e-01, 0.0000e+00, 1.0010e+01, 0.0000e+00, 5.4700e-01, 6.7150e+00,\n",
       "          8.1600e+01, 2.6775e+00, 6.0000e+00, 4.3200e+02, 1.7800e+01, 3.9559e+02,\n",
       "          1.0160e+01],\n",
       "         [9.6040e-02, 4.0000e+01, 6.4100e+00, 0.0000e+00, 4.4700e-01, 6.8540e+00,\n",
       "          4.2800e+01, 4.2673e+00, 4.0000e+00, 2.5400e+02, 1.7600e+01, 3.9690e+02,\n",
       "          2.9800e+00],\n",
       "         [1.4103e-01, 0.0000e+00, 1.3920e+01, 0.0000e+00, 4.3700e-01, 5.7900e+00,\n",
       "          5.8000e+01, 6.3200e+00, 4.0000e+00, 2.8900e+02, 1.6000e+01, 3.9690e+02,\n",
       "          1.5840e+01],\n",
       "         [6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01, 6.5750e+00,\n",
       "          6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02, 1.5300e+01, 3.9690e+02,\n",
       "          4.9800e+00]]),\n",
       " tensor([26.4000, 50.0000, 22.0000,  7.2000, 19.9000, 25.0000, 22.8000, 32.0000,\n",
       "         20.3000, 24.0000])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/300], Step [36/36], Loss: 90.72222"
     ]
    }
   ],
   "source": [
    "total_step = len(train_dl)  #for printing purpose\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (data, labels) in enumerate(train_dl):  \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward pass\n",
    "        y_hat = model(data)\n",
    "#      \n",
    "        \n",
    "        loss = criterion(y_hat, labels.view(-1, 1))  #note that outputs shape [batch, num_classes]) while labels shape ([batch, ])\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()   \n",
    "        \n",
    "        #update gradient\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 6 == 0:\n",
    "            sys.stdout.write('\\rEpoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epoch, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_yhat = model(torch.FloatTensor(X_train))\n",
    "final_yhat = final_yhat.detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.00967  , 29.015322 , 20.396034 , 11.233485 , 15.263755 ,\n",
       "       21.749237 , 29.254725 , 25.154339 , 20.089449 , 29.087109 ,\n",
       "       24.103935 , 13.086896 , 28.512547 ,  9.75282  , 29.546942 ,\n",
       "       21.660011 , 25.394604 , 21.457478 , 24.426897 ,  9.982354 ,\n",
       "       19.39489  , 18.360893 , 33.261425 ,  2.7118273, 24.392748 ,\n",
       "       18.580584 , 22.840246 , 27.838388 , 24.800522 , 31.439762 ,\n",
       "       23.385416 , 30.221468 , 23.610353 , 14.405337 , 25.155867 ,\n",
       "       24.658539 , 20.768032 , 12.444699 , 14.445821 , 21.185764 ,\n",
       "       10.041176 , 14.497876 , 30.22368  , 20.903114 , 25.917723 ,\n",
       "       22.039082 , 28.778955 ,  8.57257  , 24.940117 , 24.39798  ,\n",
       "       15.37675  , 16.991955 ,  9.479245 , 25.840862 , 18.549465 ,\n",
       "       31.877716 , 24.049004 , 21.016006 , 31.613398 , 21.61774  ,\n",
       "       13.212491 , 13.221108 , 23.816484 , 21.187317 ,  7.890893 ,\n",
       "        8.269265 , 19.714943 , 25.751335 , 21.005432 , 30.718475 ,\n",
       "       33.965797 , 29.850899 , 15.249267 , 26.032711 , 31.438435 ,\n",
       "       22.75561  , 18.549278 , 15.021512 , 26.55965  ,  8.761853 ,\n",
       "       19.87898  , 19.756742 , 24.105713 , 28.337248 , 26.002613 ,\n",
       "       24.432217 , 18.13138  , 14.252498 , 27.97594  , 27.43862  ,\n",
       "       28.983986 , 20.599468 , 23.601788 , 23.523224 , 14.180678 ,\n",
       "       22.766497 , 14.185335 , 33.25404  , 12.995577 , 27.126534 ,\n",
       "       19.275476 ,  9.784335 , 13.064635 , 10.787927 , 27.856583 ,\n",
       "       20.684486 , 29.073269 , 15.786891 , 25.673962 , 25.395802 ,\n",
       "       19.678802 , 24.236032 , 28.149446 , 27.6528   , 12.327733 ,\n",
       "       31.466778 , 23.216364 , 27.269613 , 32.963512 , 17.962809 ,\n",
       "       20.356287 , 31.977554 , 19.603407 , 32.133106 , 22.423618 ,\n",
       "       24.65731  , 13.840356 , 32.446728 , 30.134462 , 21.339266 ,\n",
       "       25.012037 , 23.32797  , 14.869555 , 12.678401 , 24.971136 ,\n",
       "       26.144949 , 26.883562 , 32.662884 , 23.585285 , 25.113876 ,\n",
       "       26.4666   , 20.20742  , 22.282131 , 28.295984 , 26.628819 ,\n",
       "       31.245102 ,  7.093829 ,  8.27086  , 26.279024 , 19.402756 ,\n",
       "       20.468948 , 15.523636 , 27.631063 , 23.314262 , 27.025307 ,\n",
       "       31.307629 , 15.471675 , 16.814747 , 36.916813 , 19.504839 ,\n",
       "       29.716238 , 23.559021 , 27.789272 , 20.690748 ,  7.3409395,\n",
       "       30.976744 , 26.338701 , 24.375408 , 17.94586  , 17.466267 ,\n",
       "       16.24984  , 18.190262 , 25.653135 , 29.5896   , 35.976234 ,\n",
       "       17.345177 , 30.239477 , 20.673386 ,  9.12823  , 30.221697 ,\n",
       "       13.540578 , 20.474312 , 24.208815 , 30.313034 , 12.586068 ,\n",
       "       25.697361 , 16.927828 , 28.152496 , 15.098056 , 21.027052 ,\n",
       "       23.088282 , 27.370113 , 14.604955 , 25.201313 , 17.168678 ,\n",
       "       23.424442 , 20.400217 , 18.284626 , 33.423798 , 21.065739 ,\n",
       "       23.701141 , 24.940018 , 11.85323  , 30.196651 , 26.839022 ,\n",
       "       25.500591 , 27.503149 , 27.288017 , 23.234024 , 18.924877 ,\n",
       "        7.266305 , 23.044561 , 16.935493 , 13.063609 , 22.087112 ,\n",
       "       29.000057 , 16.038506 , 13.644259 , 30.904865 , 26.32402  ,\n",
       "       28.05815  , 25.201803 , 28.43404  , 21.129072 , 30.31612  ,\n",
       "       13.526286 , 24.011158 , 25.857567 , 16.341711 ,  8.284291 ,\n",
       "       29.345669 , 24.396336 , 11.908635 , 23.030104 , 18.620193 ,\n",
       "       18.68767  , 23.05651  ,  1.894457 , 19.805227 , 22.15366  ,\n",
       "       29.937325 , 33.83405  , 26.712175 , 12.68603  , 27.152477 ,\n",
       "       22.975555 ,  4.8540583, 30.93071  , 21.597992 , 20.91496  ,\n",
       "       25.321705 , 29.579626 , 19.319866 , 12.933179 , 29.786308 ,\n",
       "       25.863316 , 20.578617 , 20.615828 , 26.978184 , 20.437733 ,\n",
       "       12.494935 , 14.337927 , 27.207764 , 27.495617 , 32.402332 ,\n",
       "       28.111553 , 25.784668 , 20.94357  , 12.5837965, 11.365291 ,\n",
       "       19.683502 ,  5.9670057, 13.930509 , 15.958173 , 20.460226 ,\n",
       "       35.04414  , 26.394451 ,  7.6857176, 26.418207 , 19.303719 ,\n",
       "       15.812397 , 11.595988 , 19.982258 , 25.020287 , 29.035261 ,\n",
       "       30.615984 , 22.340046 , 28.816856 , 20.32984  , 18.646927 ,\n",
       "       19.805473 , 24.814087 , 18.335562 , 21.300156 , 31.857855 ,\n",
       "       17.307014 , 28.141378 , 25.209087 , 24.169231 , 24.709276 ,\n",
       "       20.672462 , 10.162496 , 16.286144 , 16.545187 , 28.435871 ,\n",
       "       29.638145 , 10.51094  , 23.155502 , 24.250036 , 21.286331 ,\n",
       "       26.124554 , 29.079062 , 14.123063 , 21.898338 , 21.179781 ,\n",
       "       25.261852 , 22.625273 , 22.061771 , 12.760772 , 17.348335 ,\n",
       "       26.325842 , 24.994442 , 20.063805 , 19.105629 , 28.322453 ,\n",
       "       12.003358 , 34.56129  , 24.167444 , 23.247707 , 17.224457 ,\n",
       "       19.498539 , 16.504341 , 22.165005 , 24.136526 ,  5.1438665,\n",
       "       23.552599 , 22.081522 , 28.902956 , 24.988863 , 30.274185 ,\n",
       "       31.291115 , 16.567108 , 23.307247 , 21.632887 , 27.935184 ,\n",
       "       22.348686 , 25.472687 , 25.969294 , 28.351383 , 25.481087 ,\n",
       "       12.8478   , 30.482014 , 14.459994 , 28.894175 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.68940573011265\n",
      "0.6012897677969486\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_pred = final_yhat, y_true = y_train))\n",
    "print(r2_score(y_pred = final_yhat, y_true = y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use NN model to predict X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nntestHat  = model(torch.FloatTensor(X_test)).detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.138145317518386\n",
      "0.5825253664732106\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_pred = nntestHat, y_true = y_test))\n",
    "print(r2_score(y_pred = nntestHat, y_true = y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with ML sklearn linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skmodel = LinearRegression()\n",
    "skmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_train_pred = skmodel.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.007700342563332\n",
      "0.7395414040801704\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_pred = sk_train_pred, y_true = y_train))\n",
    "print(r2_score(y_pred = sk_train_pred, y_true = y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.16688055e-01,  3.99265259e-02,  9.34493581e-03,  3.68419504e+00,\n",
       "       -2.18044555e+01,  2.73443676e+00,  2.40102302e-02, -1.48726638e+00,\n",
       "        3.26298410e-01, -1.05942855e-02, -1.02550914e+00,  9.44131156e-03,\n",
       "       -6.42251374e-01])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skmodel.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_test_pred  = skmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.531914539154286\n",
      "0.7204184424179227\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_pred = sk_test_pred, y_true = y_test))\n",
    "print(r2_score(y_pred = sk_test_pred, y_true = y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from the results above, nn outperforms ml in sklearn both in training and test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
