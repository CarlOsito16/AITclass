{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "Modify the Bagging scratch code in our lecture such that:\n",
    "- Calculate for oob evaluation for each bootstrapped dataset, and also the average score\n",
    "- Change the code to \"without replacement\"\n",
    "- Put everything into a class <code>Bagging</code>.  It should have at least two methods, <code>fit(X_train, y_train)</code>, and <code>predict(X_test)</code>\n",
    "- Modify the code from above to randomize features.  Set the number of features to be used in each tree to be <code>sqrt(n)</code>, and then select a subset of features for each tree.  This can be easily done by setting our DecisionTreeClassifier <code>max_features</code> to 'sqrt'\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VuyGmG6CYv-3"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zV2YERKYY8w_",
    "outputId": "493309e2-fa18-425f-cdb0-4a1a76fa6094"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try doing the task without not putting in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrERLghna1px",
    "outputId": "978ad476-ff00-49f0-f006-77f088f09e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy oob score of 0 tree: 0.9523809523809523\n",
      "\n",
      "Accuracy oob score of 1 tree: 0.9047619047619048\n",
      "\n",
      "Accuracy oob score of 2 tree: 0.9047619047619048\n",
      "\n",
      "Accuracy oob score of 3 tree: 0.9523809523809523\n",
      "\n",
      "Accuracy oob score of 4 tree: 0.9523809523809523\n",
      "\n",
      "Average oob score after of 5 trees : 0.9333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "B = 5\n",
    "m, n = X_train.shape\n",
    "boostrap_ratio = 0.8\n",
    "tree_params = {'max_depth': 2, 'criterion':'gini', 'max_features': 'sqrt'}\n",
    "models = [DecisionTreeClassifier(**tree_params) for _ in range(B)]\n",
    "\n",
    "#sample size for each tree\n",
    "sample_size = int(boostrap_ratio * len(X_train))\n",
    "\n",
    "xsamples = np.zeros((B, sample_size, n)) # make sure to contain the number of trees you have upfront\n",
    "ysamples = np.zeros((B, sample_size))\n",
    "\n",
    "oob_xsamples = []\n",
    "oob_ysamples = []\n",
    "oob_accuracy = []\n",
    "with_replacement = False\n",
    "\n",
    "\n",
    "#subsamples for each model\n",
    "\n",
    "for i in range(B):\n",
    "    ##sampling with replacement; i.e., sample can occur more than once\n",
    "    #for the same predictor\n",
    "    idx_used = []\n",
    "    oob = []\n",
    "    check_set = np.zeros((m), dtype= bool)\n",
    "    for j in range(sample_size):\n",
    "        idx = random.randrange(m)   \n",
    "        if with_replacement:  # condition here checks if the duplicate index for each bootstrap is allowed\n",
    "          pass\n",
    "        else:\n",
    "          while idx in idx_used: # if the index already is used, then it must be regenerated and check again\n",
    "            idx = random.randrange(m)\n",
    "\n",
    "        xsamples[i, j, :] = X_train[idx]\n",
    "        ysamples[i, j] = y_train[idx]\n",
    "        idx_used.append(idx)\n",
    "        oob.append(idx)\n",
    "        \n",
    "\n",
    "        #keep track of idx that i did not use for ith tree\n",
    "    check_set[idx_used] = True\n",
    "    oob_xsamples.append(X_train[~check_set])\n",
    "    oob_ysamples.append(y_train[~check_set])\n",
    "\n",
    "\n",
    "\n",
    "    models[i] = models[i].fit(xsamples[i, :], ysamples[i])\n",
    "    val_yhat = models[i].predict(oob_xsamples[i])\n",
    "    # print(val_yhat)\n",
    "    oob_ac = accuracy_score(y_true = oob_ysamples[i], y_pred = val_yhat)\n",
    "    oob_accuracy.append(oob_ac)\n",
    "    print(f\"Accuracy oob score of {i} tree: {oob_ac}\")\n",
    "    print()\n",
    "\n",
    "print(f'Average oob score after of {B} trees : {np.mean(oob_accuracy)}')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#make prediction and return the probabilities\n",
    "predictions = np.zeros((B, X_test.shape[0]))\n",
    "for i, model in enumerate(models):\n",
    "    yhat = model.predict(X_test)\n",
    "    predictions[i, :] = yhat\n",
    "        \n",
    "yhat = stats.mode(predictions)[0][0]\n",
    "\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "q6eA9miTs0pt"
   },
   "outputs": [],
   "source": [
    "#make prediction and return the probabilities\n",
    "predictions = np.zeros((B, X_test.shape[0]))\n",
    "for i, model in enumerate(models):\n",
    "    yhat = model.predict(X_test)\n",
    "    predictions[i, :] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahLeSFvUx3vI",
    "outputId": "3255087b-1a2a-4643-f412-dea9f2c29959"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 2., 1., 1., 0., 1., 2., 1., 1., 2., 0., 0., 0., 0., 1., 2.,\n",
       "       1., 1., 2., 0., 2., 0., 2., 2., 2., 2., 2., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 2., 1., 0., 0., 0., 2., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mode(predictions, axis = 0)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5TnLiAFx4zn",
    "outputId": "6a67162b-afd1-457a-abad-1115f0ad9eda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mode(predictions, axis = 0)[0][0] == y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's put everything in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KDtsyIoWyIPn"
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "\n",
    "  def __init__(self, B, bootstrap_ratio, with_replacement):\n",
    "    self.B = B\n",
    "    self.bootstrap_ratio = bootstrap_ratio\n",
    "    self.with_replacement = with_replacement\n",
    "    self.tree_params = {'max_depth' : 2, 'max_features': 'sqrt'}\n",
    "    self.models = [DecisionTreeClassifier(**self.tree_params) for tree in range(B)]\n",
    "\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    m, n = X.shape\n",
    "\n",
    "    sample_size = int(self.bootstrap_ratio * m)\n",
    "    X_sample = np.zeros((self.B, m, n))\n",
    "    y_sample = np.zeros((self.B, m))\n",
    "    print(f\"Number of bootstrap sample: {sample_size}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "    oob_X_sample = []\n",
    "    oob_y_sample = []\n",
    "    oob_accuracy = []\n",
    "\n",
    "    for tree in range(self.B):\n",
    "      idx_used = []\n",
    "      oob_idx  = []\n",
    "      check_set = np.zeros((m), dtype = bool)\n",
    "      \n",
    "      for row in range(sample_size):\n",
    "        idx = random.randrange(m)\n",
    "\n",
    "        if self.with_replacement:\n",
    "          pass\n",
    "        else:\n",
    "          while idx in idx_used:\n",
    "            idx = random.randrange(m)\n",
    "\n",
    "\n",
    "        X_sample[tree, row, :] = X[idx, :]\n",
    "        y_sample[tree, row]   = y[idx]\n",
    "        idx_used.append(idx)\n",
    "        oob_idx.append(idx)\n",
    "        # print(len(idx_used), len(np.unique(idx_used)))\n",
    "\n",
    "\n",
    "      check_set[oob_idx] = True\n",
    "      oob_X_sample.append(X[~check_set])\n",
    "      oob_y_sample.append(y[~check_set])\n",
    "\n",
    "      print(f\"total num of idx and unique idx: {len(idx_used), len(np.unique(idx_used)) }\")\n",
    "\n",
    "\n",
    "      self.models[tree].fit(X_sample[tree, :], y_sample[tree])\n",
    "      val_yhat = self.models[tree].predict(oob_X_sample[tree])\n",
    "      oob_ac = accuracy_score(y_true = oob_y_sample[tree], y_pred = val_yhat)\n",
    "      oob_accuracy.append(oob_ac)\n",
    "      print(f\"Accuracy oob score of {tree} tree: {oob_ac}\")\n",
    "      print()   \n",
    "\n",
    "\n",
    "  def predict(self, X):\n",
    "    predictions = np.zeros((self.B, len(X)))\n",
    "    for i, model in enumerate(self.models):\n",
    "      predictions[i, : ] = model.predict(X)\n",
    "#       print(f\"y_hat of {i} tree: {predictions[i, : ]}\")\n",
    "\n",
    "    yhat = stats.mode(predictions, axis = 0)[0][0]\n",
    "    return yhat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with_replacement boostrap and boostrap_ratio at 0.75, with 5 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-1j4XBk3hoG",
    "outputId": "fe33e93e-07e9-42f2-f802-519810864bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bootstrap sample: 78\n",
      "\n",
      "total num of idx and unique idx: (78, 58)\n",
      "Accuracy oob score of 0 tree: 0.9361702127659575\n",
      "\n",
      "total num of idx and unique idx: (78, 60)\n",
      "Accuracy oob score of 1 tree: 0.8888888888888888\n",
      "\n",
      "total num of idx and unique idx: (78, 54)\n",
      "Accuracy oob score of 2 tree: 0.9019607843137255\n",
      "\n",
      "total num of idx and unique idx: (78, 56)\n",
      "Accuracy oob score of 3 tree: 0.8979591836734694\n",
      "\n",
      "total num of idx and unique idx: (78, 53)\n",
      "Accuracy oob score of 4 tree: 0.8461538461538461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = RandomForest(5,0.75 ,True)\n",
    "test.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mf9_9GljBVF9",
    "outputId": "53905f87-6a4b-40f0-86f4-60670773b2a8"
   },
   "outputs": [],
   "source": [
    "yhat= test.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try without_replacement boostrap and boostrap_ratio at 0.8, with 10 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LysoXY9Z7RfA",
    "outputId": "a61f51a6-9d5d-4400-ebb0-c86c7bd684ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bootstrap sample: 84\n",
      "\n",
      "total num of idx and unique idx: (84, 84)\n",
      "Accuracy oob score of 0 tree: 0.9047619047619048\n",
      "\n",
      "total num of idx and unique idx: (84, 84)\n",
      "Accuracy oob score of 1 tree: 1.0\n",
      "\n",
      "total num of idx and unique idx: (84, 84)\n",
      "Accuracy oob score of 2 tree: 0.8571428571428571\n",
      "\n",
      "total num of idx and unique idx: (84, 84)\n",
      "Accuracy oob score of 3 tree: 0.6666666666666666\n",
      "\n",
      "total num of idx and unique idx: (84, 84)\n",
      "Accuracy oob score of 4 tree: 0.9047619047619048\n",
      "\n",
      "total num of idx and unique idx: (84, 84)\n",
      "Accuracy oob score of 5 tree: 0.9047619047619048\n",
      "\n",
      "total num of idx and unique idx: (84, 84)\n",
      "Accuracy oob score of 6 tree: 0.9047619047619048\n",
      "\n",
      "total num of idx and unique idx: (84, 84)\n",
      "Accuracy oob score of 7 tree: 0.9523809523809523\n",
      "\n",
      "total num of idx and unique idx: (84, 84)\n",
      "Accuracy oob score of 8 tree: 0.9047619047619048\n",
      "\n",
      "total num of idx and unique idx: (84, 84)\n",
      "Accuracy oob score of 9 tree: 0.9047619047619048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test2 = RandomForest(10,0.8 ,False)\n",
    "test2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xS67mtZK8Jpm",
    "outputId": "6c41a215-9dd6-46fb-8437-1f2dc0d215da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat2=  test2.predict(X_test)\n",
    "accuracy_score(y_test, yhat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Summary\n",
    "- Notice that power of accuracy rate of random forest. Both model gives the accuracy rate at 100%!!\n",
    "- Number of unique index used in with_replacement boostrap must be less than total number index. As for without replacement, the number of total indexes and unique indexes must be equal"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "09RandomForest",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
